





import pandas as pd

data = pd.read_csv("data/processed_data.csv")






# We can see the label proportions in the full dataset
data.iloc[:, len(data.columns) - 1].value_counts(normalize=True)

# 0 - Hate speech
# 1 - Offensive language
# 2 - Neither






from experiment_helpers import mask_labels, extract_equal_proportion
import torch

data, test = extract_equal_proportion(data, proportion=0.1)

test_X = torch.tensor(test.values[:, :-1], dtype=torch.float32)
test_Y = torch.tensor(test.values[:, -1], dtype=torch.long)







from model_head import model_head

experiment_data = data.copy()

train, dev = extract_equal_proportion(experiment_data, proportion=0.1)

train_X = torch.tensor(train.values[:, :-1], dtype=torch.float32)
train_Y = torch.tensor(train.values[:, -1], dtype=torch.long)

dev_X = torch.tensor(dev.values[:, :-1], dtype=torch.float32)
dev_Y = torch.tensor(dev.values[:, -1], dtype=torch.long)

model = model_head()

model.train(train_X, train_Y, dev_X, dev_Y)






from experiment_helpers import evaluate_model

predictions = model.predict(test_X, return_predictions=True)

accuracy, recall_0, recall_1, recall_2 = evaluate_model(
    model=model, predictions=predictions, data=test_X, ground_truth=test_Y
)

print(f"Overall accuracy: {accuracy:.3f}")
print(f"Recall on hate speech: {recall_0:.3f}")
print(f"Recall on offensive language: {recall_1:.3f}")
print(f"Recall on neither: {recall_2:.3f}")



# I will be calling each proportion of masked data a scenario
scenarios = [0.9, 0.75, 0.5, 0.25, 0.10]

# Create an empty dataframe with the following data
# - scenario
# - accuracy without SLL
# - recall for each label without SSL
# - accuracy with SLL
# - recall for each label with SSL

for scenario in scenarios:
    # Define the data situation for the scenario

    experiment_data = data.copy()

    experiment_data = mask_labels(experiment_data, mask_probability=scenario)
    train, dev = extract_equal_proportion(experiment_data, proportion=0.1)

    dev_X = torch.tensor(dev.values[:, :-1])
    dev_Y = torch.tensor(dev.values[:, -1])

    unlabeled_data, labeled_data = extract_equal_proportion(
        experiment_data, proportion=1
    )

    # <Train a model without SSL>

    # Save the accuracy and recall per label

    # </Train a model without SSL>

    # <Train a model with SSL>

    while True:
        unlabeled_predictors = torch.tensor(dev.unlabeled_data[:, :-1])
        labeled_predictors = torch.tensor(dev.labeled_data[:, :-1])
        labels = torch.tensor(dev.labeled_data[:, -1])

        # Train the model on labeled

        # Predict on unlabeled

        # if any <90% probs:

        # take them into a new df

        # Promote them

        # Join this df into the labeled

        # else:

        # break

    # Once we get here, this is the final model.
    # Evaluate
    # </Train a model with SSL>
    # Write a line into the results table





